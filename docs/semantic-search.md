## Семантический поиск (по смыслу)

В Memus реализован “поиск по смыслу” для блоков на базе:
- PostgreSQL + расширение `pgvector` (хранение векторов и KNN);
- embeddings через OpenAI API.

### Что именно ищется

- Индексируются **блоки** (текст блока + контекст заголовка статьи).
- Результат поиска — **похожие блоки** (не генерация ответа).
  - Для embeddings берётся строка вида: `"<title статьи>\\n<plain text блока>"`, где plain text получается из HTML блока через `strip_html(...)`.
  - Если этот текст длиннее `SERVPY_EMBEDDING_MAX_CHARS`, он **не обрезается**, а разбивается на чанки. Embeddings считаются для каждого чанка, а итоговый embedding блока — это **усреднение** по чанкам (с L2-нормализацией), чтобы получить один вектор на блок.

### Требования

1) PostgreSQL с установленным расширением `pgvector`.
   - В БД должно выполниться `CREATE EXTENSION vector;`
   - Схема пытается создать это расширение автоматически при старте (`init_schema()`), но если у пользователя БД нет прав — семантический поиск будет недоступен.

2) Доступный провайдер embeddings (OpenAI).

### Переменные окружения

- `SERVPY_DATABASE_URL` — DSN PostgreSQL (обязателен).
- `SERVPY_OPENAI_API_KEY` / `OPENAI_API_KEY` — API key для OpenAI (обязателен).
- `SERVPY_OPENAI_EMBED_MODEL` — модель embeddings OpenAI, по умолчанию `text-embedding-3-small`.
- `SERVPY_EMBEDDING_DIM` — размерность эмбеддинга, по умолчанию `768`.
- `SERVPY_EMBEDDING_MAX_CHARS` — максимальная длина одного чанка (по умолчанию `12000`); длинный текст блока разбивается на чанки и агрегируется в один embedding.
- `SERVPY_SEMANTIC_REINDEX_CONCURRENCY` — параллелизм переиндексации (потоки), по умолчанию `4`.

Важно: размерность `SERVPY_EMBEDDING_DIM` должна совпадать с размерностью модели embeddings и с типом в БД `vector(768)` в таблице `block_embeddings`.

### Схема в БД

Создаётся таблица:
- `block_embeddings(block_id PRIMARY KEY, author_id, article_id, article_title, plain_text, embedding vector(768), updated_at)`

Если доступен индексный метод `hnsw` (зависит от версии pgvector), создаётся индекс:
- `idx_block_embeddings_embedding_hnsw ON block_embeddings USING hnsw (embedding vector_cosine_ops)`

### API

- `GET /api/search/semantic?q=...`
  - Возвращает список похожих блоков (topK, по умолчанию 30), включая `score`.

- `POST /api/search/semantic/reindex`
  - Стартует (или “подхватывает” уже запущенную) **фоновую** переиндексацию embeddings для текущего пользователя.
  - Возвращает объект задачи (`status: running|completed|failed|cooldown|cancelled`, прогресс `processed/total`, счётчики `indexed/failed`).
  - Задача продолжает выполняться даже если HTTP‑запрос оборвётся/зависнет у клиента.

- `GET /api/search/semantic/reindex/status`
  - Возвращает текущий статус/прогресс задачи переиндексации для пользователя, либо `{ "status": "idle" }`.

- `POST /api/search/semantic/reindex/cancel`
  - Запрашивает отмену текущей задачи (если она запущена) и возвращает её объект.
  - Отмена “мягкая”: задача остановится на ближайшей итерации.

Переиндексацию можно запускать не чаще, чем раз в ~10 минут: при слишком частом запуске API вернёт `status: cooldown`.

### UI → переключение режима поиска

В панели `search-panel` (в сайдбаре) справа теперь есть кнопка c иконкой `Ai`. Она переключает режим между:
  - “Классическим” поиском (`/api/search`)
  - “Семантическим” (`/api/search/semantic`).
При переключении:
  - меняется placeholder;
  - опыт сохраняется на клиенте, следующий ввод сразу делает запрос в выбранном режиме;
  - переключатель подсвечивается, когда активен семантический режим.

### Как заполнить индекс

1) Убедиться, что `pgvector` доступен (иначе endpoint будет отвечать 503).
2) Убедиться, что настроен OpenAI (ключ и модель), и что размерность совпадает с `SERVPY_EMBEDDING_DIM` и таблицей `block_embeddings`.
3) Зайти в Memus под пользователем и вызвать `POST /api/search/semantic/reindex` (или меню пользователя → “Переиндексировать поиск”).
4) Проверять прогресс через `GET /api/search/semantic/reindex/status` (в UI прогресс показывается тостом).

### Автообновление

Индекс обновляется автоматически при:
- сохранении текста блока (`update_block`),
- вставке блока с готовым контентом (payload),
- удалении блоков (удаляются и embeddings),
- переносе блока в другую статью (переиндексация переносимого поддерева).
