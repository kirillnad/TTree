# Вариант C: Яндекс.Диск как “сервер” (Edit/Save + 3‑way merge по секциям)

## Цель

Сделать схему, в которой:
- приложение хранит рабочее состояние локально (IndexedDB),
- “источник истины” для синхронизации между устройствами — файл статьи на Яндекс.Диске,
- нет фоновой очереди outbox: синхронизация выполняется только по явной команде пользователя **“Сохранить”**,
- конфликтные изменения не теряются: при конфликте секций они пишутся в историю и выделяются в UI.

## Предпосылки/ограничения

1) Авторизация: токен Яндекса хранится в `localStorage`. Права доступа между пользователями не предусмотрены.
2) В этой схеме “Сохранено” означает “записано на Яндекс.Диск”. Локальная запись в IndexedDB — не долговременная гарантия (см. iOS eviction).
3) Любые “AI‑функции” (proofread/title/embeddings) могут вызываться напрямую из клиента во внешние API, но это отдельная тема; данный документ описывает только хранение/синк статьи и конфликт‑менеджмент.

## Термины

- `base` — состояние статьи на момент начала редактирования (или на момент последнего успешного Save этой статьи).
- `draft` — текущее локальное состояние статьи (в процессе редактирования).
- `server` — текущая версия статьи на Яндекс.Диске, скачанная при сохранении.
- `merged` — результат 3‑way merge: `merge(base, draft, server)`.

## Хранилище на Яндекс.Диске (строго)

Для каждой статьи хранится один файл с JSON TipTap документа:

- Путь: `app:/articles/{articleId}.docjson`
- Содержимое: `{ docJson, updatedAtUtc }`
  - `docJson` — TipTap JSON (outline‑схема),
  - `updatedAtUtc` — время записи файла на клиенте (диагностика, не используется как арбитр).

## История (строго): папка снапшотов секций

Цель: “История блока” читается быстро, не требует парсить один большой файл и легко чистится (TTL/лимит).

Структура на Яндекс.Диске:
- статья: `app:/articles/{articleId}.docjson`
- история секций: `app:/articles/{articleId}/history/{sectionId}/...`

Файлы истории:
- `app:/articles/{articleId}/history/{sectionId}/{timestampUtc}_save.json`
- `app:/articles/{articleId}/history/{sectionId}/{timestampUtc}_conflict.json`

Где `timestampUtc` — ISO‑строка времени, пригодная для сортировки по имени (например `2026-01-10T12-34-56.789Z`).

Содержимое history‑файла (строго):
- `type`: `"save"` или `"conflict"`
- `createdAtUtc`
- `articleId`
- `sectionId`
- `reason` (только для `"conflict"`): `"rev_mismatch" | "deleted_tombstone" | "id_collision"`
- `server` (обязательно для `"conflict"`): `{ headingJson, bodyJson }`
- `draft` (обязательно для `"conflict"`): `{ headingJson, bodyJson }`
- `saved` (обязательно для `"save"`): `{ headingJson, bodyJson }`

Запись истории при Save (строго):
- для каждой секции `sectionId`, где `hash(base) != hash(merged)`:
  - создать один файл `{timestamp}_save.json` со `saved:{...}`.

Запись истории при конфликте (строго):
- для каждой конфликтной секции:
  - создать файл `{timestamp}_conflict.json` с полями `server` и `draft`.

UI требование (строго):
- “История блока…” показывает записи только для `sectionId` текущего блока (листинг папки `.../history/{sectionId}/`),
- конфликтные записи выделяются цветом и подписью “Конфликт”.

GC истории (строго):
- ограничить историю по каждой секции: хранить последние 50 файлов или TTL 90 дней (что раньше наступит),
- удаление выполняется фоново при старте приложения или после успешного Save.

## Локальные данные (IndexedDB) (строго)

Для каждой статьи `articleId` клиент хранит:
- `baseDocJson` (последняя подтверждённая база для 3‑way merge),
- `draftDocJson` (текущее состояние),
- `dirty` (boolean),
- `baseHashBySectionId` (map `sectionId -> hash(headingJson, bodyJson)`), чтобы ускорять определение изменённых секций,
- `lastServerPullAtUtc` (диагностика).

## UI и навигация (строго)

1) Редактирование свободное: пользователь может редактировать любое количество статей подряд.
2) В UI есть **одна глобальная** кнопка “Сохранить”.
3) Индикация:
   - если нет `dirty` статей → кнопка может быть disabled/скрыта (решение UI),
   - если есть `dirty` статьи → показываем счётчик `N` несохранённых статей.

## Алгоритм “Сохранить” (строго)

### 0) Определение набора статей

При нажатии “Сохранить” клиент выбирает все статьи, где `dirty=true`.

Сохранение идёт последовательно, по одной статье за раз:
- чтобы не перегружать сеть и не запутывать UX,
- чтобы проще обрабатывать конфликты.

### 1) Pull server‑версии

Для каждой dirty‑статьи:
1) скачать `serverDocJson` с Яндекс.Диска (`GET app:/articles/{articleId}.docjson`),
2) если файла нет → считать `serverDocJson = пустая статья` (first save),
3) если файл битый/непарсится → остановить сохранение этой статьи и показать ошибку.

### 2) 3‑way merge по секциям

Вход: `baseDocJson`, `draftDocJson`, `serverDocJson`.

Единица merge — секция `outlineSection` с ключом `sectionId = attrs.id`.

Для каждой секции `sectionId`, которая присутствует хотя бы в одном из трёх документов:
- вычислить `baseHash`, `draftHash`, `serverHash` (hash от `(headingJson, bodyJson)`; структура детей не входит).

Правила merge контента секции (строго):
1) Если `draftHash == serverHash` → берём `draft` (без конфликта).
2) Если `draftHash == baseHash` и `serverHash != baseHash` → берём `server` (клиент не менял, менял сервер).
3) Если `serverHash == baseHash` и `draftHash != baseHash` → берём `draft` (клиент менял, сервер нет).
4) Если `draftHash != baseHash` и `serverHash != baseHash` и `draftHash != serverHash` → **конфликт**.

Правила merge структуры (строго):
- Структуру (`parentId/position/collapsed`) берём из `serverDocJson` целиком (серверная структура побеждает).
- Исключение: если статья новая на сервере (файла не было) → структуру берём из `draftDocJson`.

Причина: структура сложна для безопасного merge без потерь; в этой схеме структура считается “быстрее меняющейся между устройствами” и берётся с диска.

### 3) Конфликты → запись в историю

Для каждой конфликтной секции `sectionId` создаём history‑файл (см. “История (строго): папка снапшотов секций” выше) и сохраняем **оба** варианта секции: `server` и `draft`.

Что делаем с конфликтной секцией в `mergedDocJson` (строго):
- по умолчанию берём `server` (чтобы не перетереть чужое),
- пользователь может позже восстановить “мой вариант” из истории (ручное действие).

### 4) Upload merged‑версии

Если merge завершился (с конфликтами или без):
1) записать `mergedDocJson` в `app:/articles/{articleId}.docjson` на Яндекс.Диск,
2) при успехе:
   - `baseDocJson = mergedDocJson`,
   - `draftDocJson = mergedDocJson`,
   - `dirty=false`.

Если upload не удался:
- статья остаётся `dirty=true`,
- пользователь получает ошибку (offline/auth/timeout),
- повторная попытка — следующий “Сохранить”.

## Картинки/вложения (строго)

Цель: до нажатия “Сохранить” все вставленные картинки должны работать оффлайн и не требовать сети; при “Сохранить” они загружаются на “бакет” (Яндекс.Диск/объектное хранилище), а в статье остаются ссылки.

### 1) Локальная вставка картинки (до Save)

- При вставке/дропе картинки клиент сохраняет файл локально (IndexedDB/Cache Storage) и вставляет в `docJson` ссылку на локальный ресурс.
- В `docJson` дополнительно хранится `localAssetId` (UUID) для этой картинки (чтобы потом найти файл для upload).

Правило (строго):
- если у картинки есть `localAssetId`, то она считается “не загружена на бакет”.

### 2) Upload картинок на бакет при Save

Во время сохранения статьи (после merge и перед upload `mergedDocJson` на Яндекс.Диск):
1) собрать все картинки/вложения в `mergedDocJson`, у которых есть `localAssetId`,
2) для каждой такой картинки загрузить бинарник на бакет по пути:
   - `app:/uploads/{articleId}/{localAssetId}.{ext}`
3) заменить в `mergedDocJson`:
   - `src` на `remoteUrl` (ссылка на бакет),
   - удалить `localAssetId`.

Если upload хотя бы одной картинки не удался:
- Save статьи считается неуспешным (не пишем `mergedDocJson` на диск),
- статья остаётся `dirty=true`,
- пользователь получает ошибку, повтор — следующий “Сохранить”.

### 3) Сборка мусора (GC) локальных картинок

После успешного Save статьи локальные assets подлежат удалению только если выполняется условие:
- в последнем сохранённом `baseDocJson` для этого `localAssetId` уже есть `remoteUrl` (т.е. картинка точно на бакете).

Дополнение (iOS Quota / LRU, строго):
- локальные картинки считаются кэшем и могут удаляться автоматически;
- критерий удаления: `lastOpenedAtUtc` (обновляется при отображении картинки в UI).

Правило очистки (строго):
1) периодически (например, при старте приложения и после открытия статьи) проверять `navigator.storage.estimate()` и долю `usage/quota`,
2) если занято > 80%:
   - удалить из локального хранилища самые “старые” картинки по `lastOpenedAtUtc` (LRU),
   - удалять только те, которые уже имеют `remoteUrl` в последнем сохранённом `baseDocJson` (иначе потеряем несохранённые вложения),
   - удалять пачками (например 50 штук) до тех пор, пока доля не станет <= 70%.

Fallback (строго):
- если нужной картинки нет локально, но в `docJson` есть `remoteUrl` → скачать с бакета и показать.

## Важно: почему “очередь не нужна”

Очередь (outbox) не нужна только при выполнении условий:
- “Сохранить” — единственный способ отправки на Яндекс.Диск,
- при уходе со страницы/закрытии вкладки, если есть dirty‑статьи, UI обязан показывать предупреждение и предотвращать случайный выход,
- пользователь принимает, что до нажатия “Сохранить” данные синхронизированы только локально.

## Ограничения Variant C (фиксируем явно)

1) Конфликты решаются не автоматическим merge текста, а записью в историю + ручным восстановлением.
2) Структура берётся с сервера (Я.Диска) и может “перепрыгнуть” относительно локальной до следующего Save.
3) Большие статьи = большие файлы: при каждом Save идёт pull+upload всего docJson.

## Открытые вопросы и ограничения Variant C (фиксируем явно)

1) Конфликты секций при 3‑way merge:
   - текущая политика: записать конфликт в историю и в `mergedDocJson` взять `server` (чтобы не перетереть чужое).
   - открытый вопрос: нужно ли вместо “server wins” показывать модалку “разрешить конфликты” перед upload (выбор для каждой секции: server/draft).

2) Удаление секций между устройствами:
   - 3‑way merge по `sectionId` не различает “секцию удалили” vs “секции не было в базе” без tombstone/deletions‑журнала.
   - Нужно решение:
     - хранить список удалённых `sectionId` в `draft` (deletions set) и учитывать его при merge,
     - или запретить удаление без немедленного Save.

3) Структура:
   - сейчас “server wins”. Если пользователь менял структуру локально, а другой клиент менял структуру на диске, локальная правка может пропасть.
   - Нужно решение: оставить “server wins” (принять) или добавить конфликт‑модалку для структуры (без истории).

4) Доступ к uploads на Яндекс.Диске:
   - нужно строго определить, как формируется `remoteUrl` и как картинка загружается в браузере:
     - публичные ссылки Я.Диска,
     - или скачивание через API с токеном (тогда нужны CORS/реализация в клиенте).

5) GC удалённых uploads на Яндекс.Диске:
   - локальный LRU решает iOS quota, но удалённые из статьи картинки останутся на диске.
   - Нужна политика очистки на бакете (TTL/пометка “referenced”).

6) Глобальная кнопка “Сохранить”:
   - нужно определить поведение при batch Save:
     - при ошибке на статье №2 — останавливаемся или продолжаем сохранять остальные статьи.

## Авто‑расшифровка аудио из Inbox (Telegram .oga)

Цель: если в секции появился аудиофайл (например `.oga` из Telegram или прикреплённый вручную), автоматически получить:
- `transcript_raw` — точная расшифровка (без выдумок),
- `transcript_clean` — литературная версия (без изменения смысла).

### Стратегия чанков (строго)

- Базовый размер чанка: **10 минут**.
- Перехлёст (overlap): **2 секунды**.
- Режем сами, если длительность > 10 минут **или** файл превышает допустимый для эндпоинта (технический лимит).

Границы чанков по времени:
- `chunk[0]`: `[0, 600s + 2s]`
- `chunk[i]` (i>0): `[i*600s - 2s, (i+1)*600s + 2s]`

### Склейка (дедуп) на стыках (строго)

Поскольку есть overlap, текст на границах может дублироваться. После получения текста чанков:
1) нормализовать пробелы/переносы строк,
2) для каждой пары `(prev, next)` сравнить:
   - хвост `prev` (например последние 30 слов),
   - начало `next` (например первые 30 слов),
3) если начало `next` совпадает с хвостом `prev` (после нормализации) — удалить совпавший префикс из `next`,
4) склеить с разделителем `\n\n`.

### Вызовы моделей (внешний сервис)

Рекомендуемая последовательность запросов:
1) Для каждого чанка: audio → `transcript_raw_chunk` (один спикер).
2) После склейки: текст → `transcript_clean` (“литературная версия”).

Причина: разделение “audio→text” и “text→литературный” даёт стабильнее результат и проще дебажится.

### Шаблоны промптов (строго)

Ниже — рекомендуемые “тексты заданий” для внешней модели. Ключевые требования:
- **не выдумывать** (никаких добавленных фактов),
- если фрагмент не разобрать → писать `[неразборчиво]`,
- один спикер (не добавлять “Спикер 1/2”).

#### 1) Audio → raw (на каждый чанк)

**Вход**: аудио‑чанк (10 минут + overlap).

**Инструкция (user prompt)**:
```
Расшифруй аудио в текст.
Условия:
- Один спикер.
- Не добавляй ничего от себя.
- Сохраняй слова максимально дословно.
- Восстанови пунктуацию и заглавные буквы.
- Делай абзацы по смыслу (без таймкодов).
- Если кусок не разобрать: напиши [неразборчиво].
```

#### 2) raw → clean (после склейки всех чанков)

**Вход**: полный `transcript_raw` текстом (уже склеенный и дедупнутый).

**Инструкция (user prompt)**:
```
Приведи текст к “литературному” виду, не меняя смысл.
Условия:
- Один спикер.
- Убери слова‑паразиты, повторы, междометия, “э-э”, “ну”, “как бы”, и т.п.
- Перепиши фразы в нормальные предложения: пунктуация, согласование, порядок слов.
- Не добавляй новых фактов.
- Имена/термины/числа сохраняй как есть.
- Если есть [неразборчиво] — оставь, но не размножай.
- Делай абзацы по смыслу.

Верни результат строго в JSON:
{
  "clean": "<литературный текст>",
  "notes": "<если есть важные замечания (например, много неразборчивого), иначе пустая строка>"
}
```

### Требования к серверу (инфраструктура)

- Нужен ключ внешней модели: `SERVPY_OPENAI_API_KEY` (или `OPENAI_API_KEY`).
- Для аудио‑входа используется `POST /v1/audio/transcriptions` (audio→raw), модель задаётся через `SERVPY_AUDIO_TRANSCRIBE_MODEL` (например `gpt-4o-mini-transcribe`).
- Для литературной правки используется `POST /v1/chat/completions` (raw→clean), модель задаётся через `SERVPY_AUDIO_CLEANUP_MODEL`.
- На сервере должны быть доступны `ffmpeg` и `ffprobe` (конвертация `.oga` и нарезка чанков).

### Как отображается результат в Inbox

- После завершения обработки плейсхолдер “Расшифровываем аудио…” удаляется.
- В секции остаётся ссылка на файл и сразу следом добавляется **только** “литературный” текст.
- Сырой текст в UI не показывается (остаётся только в `audio_transcript_jobs.raw_text` для диагностики при необходимости).

Если в одной секции несколько аудиофайлов:
- на каждый attachment создаётся отдельная задача в `audio_transcript_jobs` (dedupe по `attachment_id`),
- результат вставляется сразу **после параграфа со ссылкой** на соответствующий файл,
- порядок вставок соответствует порядку появления ссылок в тексте секции (вставка идёт “рядом” с нужной ссылкой).

## Авто‑удаление неиспользуемых вложений (GC, TTL 180 дней)

Цель: пользователь не “удаляет файлы руками”, а Memus автоматически очищает вложения, на которые **нет ссылок** в тексте статей.

Правило:
- Вложение считается “используемым”, если его `stored_path` (или публичная форма `/uploads/<article_id>/<filename>`) встречается в `articles.article_doc_json`.
- Если вложение не используется, оно помечается `unreferenced_since`.
- Если `unreferenced_since` старше **180 дней** — вложение удаляется:
  - локальные `/uploads/...` — удаляем файл с диска,
  - `app:/...` / `disk:/...` — удаляем ресурс в Яндекс.Диске,
  - затем удаляем запись из таблицы `attachments`.

Технически:
- воркер запускается на сервере автоматически и делает проход примерно раз в сутки,
- параметры: `SERVPY_ATTACHMENTS_GC_TTL_DAYS` (по умолчанию 180), `SERVPY_ATTACHMENTS_GC_INTERVAL_SECONDS` (по умолчанию 86400).
